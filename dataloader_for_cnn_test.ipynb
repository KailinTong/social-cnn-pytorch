{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.utils.data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataPreprocessorForCNN():\n",
    "    def __init__(self, input_seq_length=5, pred_seq_length=5, datasets=[i for i in range(37)], test_data_sets = [2], dev_ratio_to_test_set = 0.1, forcePreProcess=False):\n",
    "        '''\n",
    "        Initializer function for the CustomDataSetForCNN class\n",
    "        params:\n",
    "        input_seq_length : input sequence length to be considered\n",
    "        output_seq_length : output sequence length to be predicted\n",
    "        datasets : The indices of the datasets to use\n",
    "        test_data_sets : The indices of the test sets from datasets\n",
    "        dev_ratio_to_test_set : ratio of the validation set size to the test set size\n",
    "        forcePreProcess : Flag to forcefully preprocess the data again from csv files\n",
    "        '''\n",
    "        # List of data directories where raw data resides\n",
    "        self.data_dirs = ['./data/train/processed/biwi/biwi_hotel', './data/train/processed/crowds/arxiepiskopi1',\n",
    "                          './data/train/processed/crowds/crowds_zara02', './data/train/processed/crowds/crowds_zara03',\n",
    "                          './data/train/processed/crowds/students001', './data/train/processed/crowds/students003', \n",
    "                          './data/train/processed/stanford/bookstore_0',\n",
    "                          './data/train/processed/stanford/bookstore_1', './data/train/processed/stanford/bookstore_2',\n",
    "                          './data/train/processed/stanford/bookstore_3', './data/train/processed/stanford/coupa_3',\n",
    "                          './data/train/processed/stanford/deathCircle_0', './data/train/processed/stanford/deathCircle_1',\n",
    "                          './data/train/processed/stanford/deathCircle_2', './data/train/processed/stanford/deathCircle_3',\n",
    "                          './data/train/processed/stanford/deathCircle_4', './data/train/processed/stanford/gates_0',\n",
    "                          './data/train/processed/stanford/gates_1', './data/train/processed/stanford/gates_3',\n",
    "                          './data/train/processed/stanford/gates_4', './data/train/processed/stanford/gates_5',\n",
    "                          './data/train/processed/stanford/gates_6', './data/train/processed/stanford/gates_7',\n",
    "                          './data/train/processed/stanford/gates_8', './data/train/processed/stanford/hyang_4',\n",
    "                          './data/train/processed/stanford/hyang_5', './data/train/processed/stanford/hyang_6',\n",
    "                          './data/train/processed/stanford/hyang_7', './data/train/processed/stanford/hyang_9',\n",
    "                          './data/train/processed/stanford/nexus_0', './data/train/processed/stanford/nexus_1',\n",
    "                          './data/train/processed/stanford/nexus_2', './data/train/processed/stanford/nexus_3',\n",
    "                          './data/train/processed/stanford/nexus_4', './data/train/processed/stanford/nexus_7',\n",
    "                          './data/train/processed/stanford/nexus_8', './data/train/processed/stanford/nexus_9']\n",
    "        train_datasets = datasets\n",
    "        for dataset in test_data_sets:\n",
    "            train_datasets.remove(dataset)\n",
    "        self.train_data_dirs = [self.data_dirs[x] for x in train_datasets]\n",
    "        self.test_data_dirs = [self.data_dirs[x] for x in test_data_sets]\n",
    "        \n",
    "        # Number of datasets\n",
    "        self.numDatasets = len(self.data_dirs)\n",
    "        \n",
    "        # Data directory where the pre-processed pickle file resides\n",
    "        self.data_dir = './data/train/processed'\n",
    "        \n",
    "        # Store the arguments\n",
    "        self.input_seq_length = input_seq_length\n",
    "        self.pred_seq_length = pred_seq_length\n",
    "        \n",
    "        # Validation arguments\n",
    "        self.dev_fraction = dev_ratio_to_test_set\n",
    "        \n",
    "        # Buffer for storing processed data.\n",
    "        self.processed_input_output_pairs = []\n",
    "        \n",
    "        # Define the path in which the process data would be stored\n",
    "        self.processed_train_data_file = os.path.join(self.data_dir, \"trajectories_cnn_train.cpkl\")\n",
    "        self.processed_dev_data_file = os.path.join(self.data_dir, \"trajectories_cnn_dev.cpkl\")\n",
    "        self.processed_test_data_file = os.path.join(self.data_dir, \"trajectories_cnn_test.cpkl\")\n",
    "        \n",
    "        # If the file doesn't exist or forcePreProcess is true\n",
    "        if not(os.path.exists(self.processed_train_data_file)) or forcePreProcess:\n",
    "            print(\"============ Creating pre-processed training data for CNN ============\")\n",
    "            self.preprocess(self.train_data_dirs, self.processed_train_data_file)\n",
    "        if not(os.path.exists(self.processed_dev_data_file)) or not(os.path.exists(self.processed_test_data_file)) or forcePreProcess:\n",
    "            print(\"============ Creating pre-processed dev & test data for CNN ============\")\n",
    "            self.preprocess(self.test_data_dirs, self.processed_test_data_file, self.dev_fraction, self.processed_dev_data_file)\n",
    "        \n",
    "    def preprocess(self, data_dirs, data_file, dev_fraction = 0., data_file_2 = None):\n",
    "        random.seed(1) # Random seed for pedestrian permutation and data shuffling\n",
    "        for directory in data_dirs:\n",
    "            print('--> Processing dataset ' + str(directory))\n",
    "            # define path of the csv file of the current dataset\n",
    "            file_path = os.path.join(directory, 'world_pos_normalized.csv')\n",
    "            \n",
    "            # Load the data from the csv file\n",
    "            data = np.genfromtxt(file_path, delimiter=',')\n",
    "            \n",
    "            # Frame IDs of the frames in the current dataset\n",
    "            frameList = np.unique(data[0, :]).tolist()\n",
    "            numFrames = len(frameList)\n",
    "            \n",
    "            # Frame ID increment for this dataset.\n",
    "            frame_increment = np.min(np.array(frameList[1:-1]) - np.array(frameList[0:-2]))\n",
    "            \n",
    "            # For this dataset check which pedestrians exist in each frame.\n",
    "            pedsInFrameList = []\n",
    "            pedsPosInFrameList = []\n",
    "            for ind, frame in enumerate(frameList):\n",
    "                # For this frame check the pedestrian IDs.\n",
    "                pedsInFrame = data[:, data[0, :] == frame]\n",
    "                pedsList = pedsInFrame[1, :].tolist()\n",
    "                pedsInFrameList.append(pedsList)\n",
    "                # Position information for each pedestrian.\n",
    "                pedsPos = []\n",
    "                for ped in pedsList:\n",
    "                    # Extract x and y positions\n",
    "                    current_x = pedsInFrame[2, pedsInFrame[1, :] == ped][0]\n",
    "                    current_y = pedsInFrame[3, pedsInFrame[1, :] == ped][0]\n",
    "                    pedsPos.extend([current_x, current_y])\n",
    "                    if (current_x == 0.0 and current_y == 0.0):\n",
    "                        print('[WARNING] There exists a pedestrian at coordinate [0.0, 0.0]')\n",
    "                pedsPosInFrameList.append(pedsPos)\n",
    "\n",
    "            # Go over the frames in this data again to extract data.\n",
    "            ind = 0  # frame index\n",
    "            while ind < len(frameList) - (self.input_seq_length + self.pred_seq_length):\n",
    "                # List of pedestrians in this frame.\n",
    "                pedsList = pedsInFrameList[ind]\n",
    "                # Check if same pedestrians exist in the next (input_seq_length + pred_seq_length - 1) frames.\n",
    "                peds_contained = True\n",
    "                for ii in range(self.input_seq_length + self.pred_seq_length):\n",
    "                    if pedsInFrameList[ind + ii] != pedsList:\n",
    "                        peds_contained = False\n",
    "                if peds_contained:\n",
    "                    #print(str(int(self.input_seq_length + self.pred_seq_length)) + ' frames starting from Frame ' + str(int(frameList[ind])) +  ' contain pedestrians ' + str(pedsList))\n",
    "                    # Initialize numpy arrays for input-output pair\n",
    "                    data_input = np.zeros((2*len(pedsList), self.input_seq_length))\n",
    "                    data_output = np.zeros((2*len(pedsList), self.pred_seq_length))\n",
    "                    for ii in range(self.input_seq_length):\n",
    "                        data_input[:, ii] = np.array(pedsPosInFrameList[ind + ii])\n",
    "                    for jj in range(self.pred_seq_length):\n",
    "                        data_output[:, jj] = np.array(pedsPosInFrameList[ind + self.input_seq_length + jj])\n",
    "                    processed_pair = (torch.from_numpy(data_input), torch.from_numpy(data_output))\n",
    "                    self.processed_input_output_pairs.append(processed_pair)\n",
    "                    ind += self.input_seq_length +  self.pred_seq_length\n",
    "                else:\n",
    "                    ind += 1\n",
    "            '''\n",
    "            # Go over the frames in this data again to extract data.\n",
    "            ind = 0\n",
    "            \n",
    "            while ind < len(frameList) - (self.input_seq_length + self.pred_seq_length):\n",
    "                 # Check if this sequence contains consecutive frames. Otherwise skip this sequence.\n",
    "                if not frameList[ind + self.input_seq_length + self.pred_seq_length] - frameList[ind] == (self.input_seq_length + self.pred_seq_length)*frame_increment:\n",
    "                    ind += 1\n",
    "                    continue;\n",
    "                # List of pedestirans in this sequence.\n",
    "                pedsList = np.unique(np.concatenate(pedsInFrameList[ind : ind + self.input_seq_length + self.pred_seq_length])).tolist()\n",
    "                # Print the Frame numbers and pedestrian IDs in this sequence for sanity check.\n",
    "                # print(str(int(self.input_seq_length + self.pred_seq_length)) + ' frames starting from Frame ' + str(int(frameList[ind])) +  ' contain pedestrians ' + str(pedsList))\n",
    "                # Initialize numpy arrays for input-output pair\n",
    "                data_input = np.zeros((2*len(pedsList), self.input_seq_length))\n",
    "                data_output = np.zeros((2*len(pedsList), self.pred_seq_length))\n",
    "                for ii in range(self.input_seq_length):\n",
    "                    for jj in range(len(pedsList)):\n",
    "                        if pedsList[jj] in pedsInFrameList[ind + ii]:\n",
    "                            datum_index = pedsInFrameList[ind + ii].index(pedsList[jj])\n",
    "                            data_input[2*jj:2*(jj + 1), ii] = np.array(pedsPosInFrameList[ind + ii][2*datum_index:2*(datum_index + 1)])\n",
    "                for ii in range(self.pred_seq_length):\n",
    "                    for jj in range(len(pedsList)):\n",
    "                        if pedsList[jj] in pedsInFrameList[ind + self.input_seq_length + ii]:\n",
    "                            datum_index = pedsInFrameList[ind + self.input_seq_length + ii].index(pedsList[jj])\n",
    "                            data_output[2*jj:2*(jj + 1), ii] = np.array(pedsPosInFrameList[ind + self.input_seq_length + ii][2*datum_index:2*(datum_index + 1)])\n",
    "                processed_pair = (torch.from_numpy(data_input), torch.from_numpy(data_output))\n",
    "                self.processed_input_output_pairs.append(processed_pair)\n",
    "                ind += self.input_seq_length + self.pred_seq_length\n",
    "             '''\n",
    "        print('--> Original Data Size: ' + str(len(self.processed_input_output_pairs)))   \n",
    "        # Perform data augmentation\n",
    "        answer = None\n",
    "        while answer not in ('y', 'n'):\n",
    "            answer = input('Do you want to perform data augmentation? (y/n)')\n",
    "            if answer == 'y':\n",
    "                self.augment_rotate()\n",
    "                self.augment_flip()\n",
    "                self.augment_permute()\n",
    "            elif answer == 'n':\n",
    "                print('--> Skipping data augmentation')\n",
    "            else:\n",
    "                print('Please enter y or n')\n",
    "        # Shuffle data, possibly divide into train and dev sets.\n",
    "        print('--> Shuffling all data before saving')\n",
    "        random.shuffle(self.processed_input_output_pairs)\n",
    "        if dev_fraction != 0.:\n",
    "            assert(data_file_2 != None)\n",
    "            dev_size = int(len(self.processed_input_output_pairs)*dev_fraction)\n",
    "            processed_dev_set = self.processed_input_output_pairs[:dev_size]\n",
    "            processed_test_set = self.processed_input_output_pairs[dev_size:]\n",
    "            # Save processed data.\n",
    "            f = open(data_file, 'wb')\n",
    "            print('--> Dumping test data to pickle file')\n",
    "            pickle.dump(processed_test_set, f, protocol=2)\n",
    "            f.close()\n",
    "            f2 = open(data_file_2, 'wb')\n",
    "            print('--> Dumping dev data to pickle file')\n",
    "            pickle.dump(processed_dev_set, f2, protocol=2)\n",
    "            f2.close()\n",
    "            # Clear buffer\n",
    "            self.processed_input_output_pairs = []\n",
    "        else:\n",
    "            # Save processed data.\n",
    "            f = open(data_file, 'wb')\n",
    "            print('--> Dumping training data to pickle file')\n",
    "            pickle.dump(self.processed_input_output_pairs, f, protocol=2)\n",
    "            f.close()\n",
    "            # Clear buffer\n",
    "            self.processed_input_output_pairs = []\n",
    "    \n",
    "    def augment_rotate(self):\n",
    "        deg_increment_int = 30\n",
    "        print('--> Data Augmentation 1: Coordinate Rotation (' + str(deg_increment_int) +' deg increment)')\n",
    "        augmented_input_output_pairs = []\n",
    "        for processed_input_output_pair in tqdm(self.processed_input_output_pairs):\n",
    "            data_input, data_output = processed_input_output_pair[0].numpy(), processed_input_output_pair[1].numpy()\n",
    "            num_peds = int(data_input.shape[0]/2)\n",
    "            # Rotate by deg_increment deg sequentially\n",
    "            for deg in range(deg_increment_int, 360, deg_increment_int):\n",
    "                data_input_rotated = np.zeros_like(data_input)\n",
    "                data_output_rotated = np.zeros_like(data_output)\n",
    "                rad = np.radians(deg)\n",
    "                c, s = np.cos(rad), np.sin(rad)\n",
    "                Rot = np.array(((c,-s), (s, c)))\n",
    "                for ii in range(num_peds):\n",
    "                    for jj in range(self.input_seq_length):\n",
    "                        coordinates_for_this_ped = data_input[2*ii:2*(ii+1), jj]\n",
    "                        new_coordinates_for_this_ped = np.dot(Rot, coordinates_for_this_ped)\n",
    "                        data_input_rotated[2*ii:2*(ii+1), jj] = new_coordinates_for_this_ped\n",
    "                    for jj in range(self.pred_seq_length):\n",
    "                        coordinates_for_this_ped = data_output[2*ii:2*(ii+1), jj]\n",
    "                        new_coordinates_for_this_ped = np.dot(Rot, coordinates_for_this_ped)\n",
    "                        data_output_rotated[2*ii:2*(ii+1), jj] = new_coordinates_for_this_ped\n",
    "                processed_pair_rotated = (torch.from_numpy(data_input_rotated), torch.from_numpy(data_output_rotated))\n",
    "                augmented_input_output_pairs.append(processed_pair_rotated)\n",
    "        self.processed_input_output_pairs.extend(augmented_input_output_pairs)\n",
    "        print('--> Augmented Data Size: ' + str(len(self.processed_input_output_pairs)))\n",
    "    \n",
    "    def augment_flip(self):\n",
    "        print('--> Data Augmentation 2: Y Flip')\n",
    "        augmented_input_output_pairs = []\n",
    "        for processed_input_output_pair in tqdm(self.processed_input_output_pairs):\n",
    "            data_input, data_output = processed_input_output_pair[0].numpy(), processed_input_output_pair[1].numpy()\n",
    "            num_peds = int(data_input.shape[0]/2)\n",
    "            # Flip y\n",
    "            data_input_yflipped = np.zeros_like(data_input)\n",
    "            data_output_yflipped = np.zeros_like(data_output)\n",
    "            for kk in range(num_peds):\n",
    "                data_input_yflipped[2*kk, :] = data_input[2*kk, :]\n",
    "                data_input_yflipped[2*kk+1, :] = -1*data_input[2*kk+1, :]\n",
    "                data_output_yflipped[2*kk, :] = data_output[2*kk, :]\n",
    "                data_output_yflipped[2*kk+1, :] = -1*data_output[2*kk+1, :]\n",
    "            processed_pair_yflipped = (torch.from_numpy(data_input_yflipped), torch.from_numpy(data_output_yflipped))\n",
    "            augmented_input_output_pairs.append(processed_pair_yflipped)\n",
    "        self.processed_input_output_pairs.extend(augmented_input_output_pairs)\n",
    "        print('--> Augmented Data Size: ' + str(len(self.processed_input_output_pairs)))\n",
    "        \n",
    "    def augment_permute(self):\n",
    "        # Specify how many pedestrian permutations to consider per input-output pair\n",
    "        num_perms = 4\n",
    "        print('--> Data Augmentation 3: Pedestrian Permutation (' + str(num_perms) + ' random permutations per input-output pair)')\n",
    "        augmented_input_output_pairs = []\n",
    "        for processed_input_output_pair in tqdm(self.processed_input_output_pairs):\n",
    "            data_input, data_output = processed_input_output_pair[0].numpy(), processed_input_output_pair[1].numpy()\n",
    "            num_peds = int(data_input.shape[0]/2)\n",
    "            for ii in range(num_perms):\n",
    "                perm = np.random.permutation(num_peds)\n",
    "                data_input_permuted = np.zeros_like(data_input)\n",
    "                data_output_permuted = np.zeros_like(data_output)\n",
    "                for jj in range(len(perm)):\n",
    "                    data_input_permuted[2*jj:2*(jj+1), :] = data_input[2*perm[jj]:2*(perm[jj]+1), :]\n",
    "                    data_output_permuted[2*jj:2*(jj+1), :] = data_output[2*perm[jj]:2*(perm[jj]+1), :]\n",
    "                processed_pair_permuted = (torch.from_numpy(data_input_permuted), torch.from_numpy(data_output_permuted))\n",
    "                augmented_input_output_pairs.append(processed_pair_permuted)\n",
    "        self.processed_input_output_pairs.extend(augmented_input_output_pairs)\n",
    "        print('--> Augmented Data Size: ' + str(len(self.processed_input_output_pairs)))\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Creating pre-processed training data for CNN ============\n",
      "--> Processing dataset ./data/train/processed/biwi/biwi_hotel\n",
      "--> Processing dataset ./data/train/processed/crowds/arxiepiskopi1\n",
      "--> Processing dataset ./data/train/processed/crowds/crowds_zara03\n",
      "--> Processing dataset ./data/train/processed/crowds/students001\n",
      "--> Processing dataset ./data/train/processed/crowds/students003\n",
      "--> Processing dataset ./data/train/processed/stanford/bookstore_0\n",
      "--> Processing dataset ./data/train/processed/stanford/bookstore_1\n",
      "--> Processing dataset ./data/train/processed/stanford/bookstore_2\n",
      "--> Processing dataset ./data/train/processed/stanford/bookstore_3\n",
      "--> Processing dataset ./data/train/processed/stanford/coupa_3\n",
      "--> Processing dataset ./data/train/processed/stanford/deathCircle_0\n",
      "--> Processing dataset ./data/train/processed/stanford/deathCircle_1\n",
      "--> Processing dataset ./data/train/processed/stanford/deathCircle_2\n",
      "--> Processing dataset ./data/train/processed/stanford/deathCircle_3\n",
      "--> Processing dataset ./data/train/processed/stanford/deathCircle_4\n",
      "--> Processing dataset ./data/train/processed/stanford/gates_0\n",
      "--> Processing dataset ./data/train/processed/stanford/gates_1\n",
      "--> Processing dataset ./data/train/processed/stanford/gates_3\n",
      "--> Processing dataset ./data/train/processed/stanford/gates_4\n",
      "--> Processing dataset ./data/train/processed/stanford/gates_5\n",
      "--> Processing dataset ./data/train/processed/stanford/gates_6\n",
      "--> Processing dataset ./data/train/processed/stanford/gates_7\n",
      "--> Processing dataset ./data/train/processed/stanford/gates_8\n",
      "--> Processing dataset ./data/train/processed/stanford/hyang_4\n",
      "--> Processing dataset ./data/train/processed/stanford/hyang_5\n",
      "--> Processing dataset ./data/train/processed/stanford/hyang_6\n",
      "--> Processing dataset ./data/train/processed/stanford/hyang_7\n",
      "--> Processing dataset ./data/train/processed/stanford/hyang_9\n",
      "--> Processing dataset ./data/train/processed/stanford/nexus_0\n",
      "--> Processing dataset ./data/train/processed/stanford/nexus_1\n",
      "--> Processing dataset ./data/train/processed/stanford/nexus_2\n",
      "--> Processing dataset ./data/train/processed/stanford/nexus_3\n",
      "--> Processing dataset ./data/train/processed/stanford/nexus_4\n",
      "--> Processing dataset ./data/train/processed/stanford/nexus_7\n",
      "--> Processing dataset ./data/train/processed/stanford/nexus_8\n",
      "--> Processing dataset ./data/train/processed/stanford/nexus_9\n",
      "--> Original Data Size: 383\n",
      "Do you want to perform data augmentation? (y/n)i\n",
      "Please enter y or n\n",
      "Do you want to perform data augmentation? (y/n)y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 106/383 [00:00<00:00, 1055.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Data Augmentation 1: Coordinate Rotation (30 deg increment)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 383/383 [00:00<00:00, 1172.83it/s]\n",
      "100%|██████████| 4596/4596 [00:00<00:00, 30296.11it/s]\n",
      "  0%|          | 0/9192 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Augmented Data Size: 4596\n",
      "--> Data Augmentation 2: Y Flip\n",
      "--> Augmented Data Size: 9192\n",
      "--> Data Augmentation 3: Pedestrian Permutation (4 random permutations per input-output pair)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9192/9192 [00:01<00:00, 9191.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Augmented Data Size: 45960\n",
      "--> Shuffling all data before saving\n",
      "--> Dumping training data to pickle file\n",
      "============ Creating pre-processed dev & test data for CNN ============\n",
      "--> Processing dataset ./data/train/processed/crowds/crowds_zara02\n",
      "--> Original Data Size: 8\n",
      "Do you want to perform data augmentation? (y/n)y\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 835.06it/s]\n",
      "100%|██████████| 96/96 [00:00<00:00, 22266.95it/s]\n",
      "100%|██████████| 192/192 [00:00<00:00, 8342.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Data Augmentation 1: Coordinate Rotation (30 deg increment)\n",
      "--> Augmented Data Size: 96\n",
      "--> Data Augmentation 2: Y Flip\n",
      "--> Augmented Data Size: 192\n",
      "--> Data Augmentation 3: Pedestrian Permutation (4 random permutations per input-output pair)\n",
      "--> Augmented Data Size: 960\n",
      "--> Shuffling all data before saving\n",
      "--> Dumping test data to pickle file\n",
      "--> Dumping dev data to pickle file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "processed = CustomDataPreprocessorForCNN(forcePreProcess=True, test_data_sets=[2], dev_ratio_to_test_set=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file = open(processed.processed_train_data_file, 'rb')\n",
    "dev_file = open(processed.processed_dev_data_file, 'rb')\n",
    "test_file = open(processed.processed_test_data_file, 'rb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/train/processed/trajectories_cnn_train.cpkl'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed.processed_train_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(train_file)\n",
    "dev = pickle.load(dev_file)\n",
    "test = pickle.load(test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2273"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDatasetForCNN(torch.utils.data.Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.file = open(self.file_path, 'rb')\n",
    "        self.data = pickle.load(self.file)\n",
    "        self.file.close()\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        item = self.data[index]\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)     \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CustomDatasetForCNN(processed.processed_train_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_set.__getitem__(99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1771, 0.1612, 0.1471, 0.1313, 0.1158],\n",
       "        [0.6733, 0.6807, 0.6873, 0.6947, 0.6982]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[ 0.1777,  0.1773,  0.1773,  0.1773,  0.1773],\n",
       "          [ 0.3633,  0.3771,  0.3907,  0.4044,  0.4180],\n",
       "          [ 0.1191,  0.1191,  0.1191,  0.1191,  0.1191],\n",
       "          [ 0.0447,  0.0447,  0.0447,  0.0447,  0.0447],\n",
       "          [ 0.0983,  0.0983,  0.0983,  0.0983,  0.0983],\n",
       "          [ 0.0544,  0.0544,  0.0544,  0.0544,  0.0544],\n",
       "          [ 0.0721,  0.0721,  0.0721,  0.0721,  0.0721],\n",
       "          [ 0.0598,  0.0598,  0.0598,  0.0598,  0.0598],\n",
       "          [ 0.0661,  0.0661,  0.0661,  0.0661,  0.0661],\n",
       "          [ 0.0401,  0.0401,  0.0401,  0.0401,  0.0401],\n",
       "          [-0.3741, -0.3772, -0.3802, -0.3820, -0.3850],\n",
       "          [ 0.7355,  0.7404,  0.7452,  0.7528,  0.7576],\n",
       "          [ 0.1136,  0.1219,  0.1327,  0.1418,  0.1506],\n",
       "          [ 0.2656,  0.2787,  0.2928,  0.3077,  0.3223],\n",
       "          [-0.1503, -0.1503, -0.1503, -0.1503, -0.1503],\n",
       "          [ 0.2184,  0.2184,  0.2184,  0.2184,  0.2184],\n",
       "          [ 0.1071,  0.1047,  0.1019,  0.0973,  0.0945],\n",
       "          [ 0.1414,  0.1318,  0.1213,  0.1115,  0.1009],\n",
       "          [-0.3563, -0.3442, -0.3333, -0.3211, -0.3089],\n",
       "          [ 0.3558,  0.3501,  0.3450,  0.3393,  0.3337],\n",
       "          [-0.3431, -0.3309, -0.3183, -0.3079, -0.2957],\n",
       "          [ 0.3773,  0.3716,  0.3657,  0.3608,  0.3552],\n",
       "          [ 0.5520,  0.5376,  0.5229,  0.5083,  0.4938],\n",
       "          [-0.0797, -0.0730, -0.0683, -0.0632, -0.0581],\n",
       "          [ 0.5622,  0.5479,  0.5339,  0.5187,  0.5048],\n",
       "          [-0.0624, -0.0557, -0.0492, -0.0455, -0.0390],\n",
       "          [-0.1782, -0.1782, -0.1782, -0.1782, -0.1782],\n",
       "          [ 0.2450,  0.2450,  0.2450,  0.2450,  0.2450],\n",
       "          [-0.2274, -0.2204, -0.2118, -0.2031, -0.1961],\n",
       "          [ 0.6118,  0.6086,  0.6079,  0.6038,  0.6006],\n",
       "          [ 0.1273,  0.1273,  0.1273,  0.1273,  0.1273],\n",
       "          [ 0.3936,  0.3936,  0.3936,  0.3936,  0.3936],\n",
       "          [ 0.0215,  0.0267,  0.0336,  0.0390,  0.0456],\n",
       "          [ 0.1281,  0.1393,  0.1497,  0.1612,  0.1718],\n",
       "          [ 0.0363,  0.0432,  0.0502,  0.0573,  0.0642],\n",
       "          [ 0.1178,  0.1282,  0.1385,  0.1493,  0.1596],\n",
       "          [-0.1054, -0.1002, -0.0963, -0.0911, -0.0871],\n",
       "          [-0.1497, -0.1384, -0.1301, -0.1190, -0.1105],\n",
       "          [ 0.6444,  0.6305,  0.6162,  0.6005,  0.5866],\n",
       "          [-0.0075, -0.0010,  0.0057,  0.0130,  0.0195],\n",
       "          [ 0.0957,  0.0957,  0.0957,  0.0957,  0.0957],\n",
       "          [ 0.4645,  0.4645,  0.4645,  0.4645,  0.4645],\n",
       "          [-0.7535, -0.7592, -0.7636, -0.7692, -0.7735],\n",
       "          [-0.3529, -0.3469, -0.3415, -0.3354, -0.3266]]], dtype=torch.float64),\n",
       " tensor([[[ 0.1773,  0.1708,  0.1627,  0.1535,  0.1446],\n",
       "          [ 0.4180,  0.4312,  0.4422,  0.4499,  0.4579],\n",
       "          [ 0.1191,  0.1191,  0.1191,  0.1191,  0.1191],\n",
       "          [ 0.0447,  0.0447,  0.0447,  0.0447,  0.0447],\n",
       "          [ 0.0983,  0.0983,  0.0983,  0.0983,  0.0983],\n",
       "          [ 0.0544,  0.0544,  0.0544,  0.0544,  0.0544],\n",
       "          [ 0.0721,  0.0721,  0.0721,  0.0721,  0.0721],\n",
       "          [ 0.0598,  0.0598,  0.0598,  0.0598,  0.0598],\n",
       "          [ 0.0661,  0.0661,  0.0661,  0.0661,  0.0661],\n",
       "          [ 0.0401,  0.0401,  0.0401,  0.0401,  0.0401],\n",
       "          [-0.3850, -0.3880, -0.3902, -0.3928, -0.3959],\n",
       "          [ 0.7576,  0.7624,  0.7669,  0.7749,  0.7797],\n",
       "          [ 0.1506,  0.1589,  0.1667,  0.1731,  0.1780],\n",
       "          [ 0.3223,  0.3355,  0.3523,  0.3706,  0.3853],\n",
       "          [-0.1503, -0.1503, -0.1503, -0.1503, -0.1503],\n",
       "          [ 0.2184,  0.2184,  0.2184,  0.2184,  0.2184],\n",
       "          [ 0.0945,  0.0906,  0.0841,  0.0745,  0.0667],\n",
       "          [ 0.1009,  0.0925,  0.0921,  0.0898,  0.0866],\n",
       "          [-0.3089, -0.2981, -0.2859, -0.2724, -0.2619],\n",
       "          [ 0.3337,  0.3286,  0.3229,  0.3200,  0.3152],\n",
       "          [-0.2957, -0.2831, -0.2727, -0.2605, -0.2483],\n",
       "          [ 0.3552,  0.3493,  0.3444,  0.3387,  0.3331],\n",
       "          [ 0.4938,  0.4799,  0.4659,  0.4507,  0.4364],\n",
       "          [-0.0581, -0.0516, -0.0451, -0.0414, -0.0347],\n",
       "          [ 0.5048,  0.4926,  0.4774,  0.4635,  0.4491],\n",
       "          [-0.0390, -0.0333, -0.0296, -0.0231, -0.0164],\n",
       "          [-0.1782, -0.1782, -0.1782, -0.1782, -0.1782],\n",
       "          [ 0.2450,  0.2450,  0.2450,  0.2450,  0.2450],\n",
       "          [-0.1961, -0.1877, -0.1807, -0.1716, -0.1633],\n",
       "          [ 0.6006,  0.6005,  0.5973,  0.5930,  0.5925],\n",
       "          [ 0.1273,  0.1273,  0.1273,  0.1256,  0.1256],\n",
       "          [ 0.3936,  0.3936,  0.3936,  0.3944,  0.3944],\n",
       "          [ 0.0456,  0.0518,  0.0579,  0.0631,  0.0679],\n",
       "          [ 0.1718,  0.1829,  0.1937,  0.2049,  0.2128],\n",
       "          [ 0.0642,  0.0712,  0.0783,  0.0853,  0.0923],\n",
       "          [ 0.1596,  0.1700,  0.1807,  0.1911,  0.2015],\n",
       "          [-0.0871, -0.0816, -0.0777, -0.0725, -0.0685],\n",
       "          [-0.1105, -0.0987, -0.0902, -0.0791, -0.0707],\n",
       "          [ 0.5866,  0.5723,  0.5566,  0.5426,  0.5288],\n",
       "          [ 0.0195,  0.0262,  0.0335,  0.0400,  0.0464],\n",
       "          [ 0.0957,  0.0957,  0.0957,  0.0957,  0.0957],\n",
       "          [ 0.4645,  0.4645,  0.4645,  0.4645,  0.4645],\n",
       "          [-0.7735, -0.7766, -0.7814, -0.7844, -0.7905],\n",
       "          [-0.3266, -0.3149, -0.3025, -0.2908, -0.2813]]], dtype=torch.float64)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_set.__getitem__(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56592"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
